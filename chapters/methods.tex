\section{Methods}
Vision Transformers (ViTs) form the backbone of all models that will be trained in this thesis.
They were introduced by \citep{Dosovitskiy2020} and transfer the concept of text transformers developed by \citep{Vaswani2017} to the image (classification) domain.
ViTs will be used in this thesis in conjunction with the DINO model objective, which resembles a paradigm of training SSL models on image data \citep{Caron2021}.
The name DINO stands for \textbf{di}stilled knowledge with \textbf{no} labels and consists of a student and a teacher network, where the teacher network is updated by the exponential moving average of the student's weights \citep{Caron2021}.
\subsection{Dataset}
In this thesis, the CheXpert dataset is used as a collection of chest X-ray images developed by \citep{Irvin2019}.
The following subsection will describe the dataset and summarize the label extraction methods of radiology reports of the authors in more detail.
Further, the reasoning behind the choice of used dataset splits is explained. 
CheXpert is an extensive collection of both frontal and lateral chest X-ray images with 224,316 images in total which were obtained from 65,240 patients.
The dataset contains labels of 12 common chest- and lung pathologies, the control class "No Finding" and the "Support Devices" class which adds up to 14 total classes \citep{Irvin2019}.
CheXpert is a multilabel dataset, which means that in each image multiple pathologies may be present.
For each image, the pathologies are labelled as positive (1), negative (0) or uncertain (-1), where uncertainty labels express both contradictions in the report and diagnostic uncertainty of the radiologist who has written the report \citep{Irvin2019}.
\par
Labels were extracted from free text radiology reports in three stages.
In the first step, observations were extracted from the reports with the help of a hand-selected list of common phrases, reviewed by different board-certified radiologists \citep{Irvin2019}.
The extracted observations are then passed to a second stage.
This stage is split into a three steps pipeline, where observations are matched against pre-negation uncertainty rules first, then against negation rules and finally against post-negation uncertainty rules \citep{Irvin2019}.
Only if an observation does not match any of the rules, it is assigned a positive label \citep{Irvin2019}.
Those rules are extracted through NLP techniques and details can be found in \citep{Irvin2019}.
In the last step, mentions are aggregated into a final label for each image and each class.
Observations with at least one positively labelled mention are assigned an aggregated positive label and an uncertainty label is selected if there is no positive mention and a minimum of one mention of uncertainty in the observations \citep{Irvin2019}.
Negative labels are only assigned if at least one mention label is negative \citep{Irvin2019}. 
If there is overall no mention of an observation, a \textit{blank} label is set as the label of the respective class \citep{Irvin2019}.
\par
Both the multilabel structure and the number of different classes of the CheXpert dataset leave room for designing various ID and OOD split settings.
For novel disease detection, \citep{Berger2021} developed two different settings for the CheXpert dataset and for the NIH ChestX-ray8 dataset \citep{Wang2017} another setting can be found in \citep{Cao2020}.
In this thesis a total of three settings are used.
In the first setting, the "No Finding" class is used as the in-distribution class, while a total of six pathologies is used as the out-of-distribution class.
Specifically, the model is trained on the "No Finding" class and performance metrics are separately evaluated on each of the six classes.
The out-of-distribution classes are Cardiomegaly, Fracture, Lung Opacity, Pleural Effusion, Pneumothorax and Support Devices.
Further, the two different settings of \citep{Berger2021} are used.
CheXpert labels are structured in a hierarchical way.
For example, the pathologies Atelectasis, Edema, Consolidation, Lung Lesion and Pneumonia can be considered as special cases of the Lung Opacity class [Fleischner ?].
The label extraction method is summarized in figure \ref{fig:multilabel-struc}.
\loadFigure{Figure:multilabel-struc}
\loadTable{Table:chexpert-concurrence-matrix}
\loadTable{Table:dataset-splits}

%\loadTable{Table:settings-dataset-sizes1}
%\loadTable{Table:settings-dataset-sizes2}
%\loadTable{Table:settings-dataset-sizes3}
\loadTable{Table:settings-dataset-sizes}
\subsection{Out-Of-Distribution Detection}
xx

\subsection{Pathologies}
Medical Imaging datasets are very different to standard benchmark imaging datasets like CIFAR-10.
In particular, classifying the underlying labels is challenging for non-experts [QUELLE], while classifying (coarse) labels for datasets like CIFAR-10 is often considered to be "easy" [QUELLE].
Therefore, domain knowledge is advantageous and can result in better performance when designing the model architecture or the data augmentations and can result in better performance.
\par
In this subsection, six different conditions are briefly discussed providing basic medical knowledge about the CheXpert labels contained in different ID-OOD settings in this master thesis.
The label names are taken from the CheXpert dataset \citep{Irvin2019} and adhere to the glossary of the Fleischner Society for thoracic imaging \citep{Hansell2008}.
\par
Cardiomegaly is the first condition of interest. The collective term refers to all sorts of heart enlargements [RADIOPAE.].
Pneumothorax is another medical condition that will be used as an in-distribution pathology.
It is associated to the pleural space, which is ... [QUELLE, ergänzen] and is also called pleural cavity.
If the pleural space is filled with gas (frequently air) [RADIOPAE.] the medical term is Pneumothorax.
Rib fractures refer to a broken rib bone [QUELLE, wird oft übersehen ergänzen].
A Pleural Effusion is the medical expression for an irregular fluid conglomeration in the pleural cavity [RADIOPAE.].
Lung Opacity describes .. \\
Pneumonia is another lung disease and refers as a broad term to an infection within a lung [RADIOPAE.]. 
%Figure of pathologies
\loadFigure{Figure:pathologies}

\subsection{Vision Transformers}
Vision Transformers are based on the transformer architecture and reformulate the attention mechanism designed in \cite{Vaswani2017} to images.
Whereas text transformer split a sequence of natural language into tokens, Vision Transformers split images into a fixed number of image patches \citep{Dosovitskiy2020}.
\\
The flattened image patches represent the token sequence which is passed to the transformer encoder architecture.
The encoder itself consists of a number of stacked transformer blocks, where each block contains linear layers, normalization layers and attention \citep{Vaswani2017,Dosovitskiy2020}.
\\
These patches are fed into a neural network architecture that consists of a number of stacked transformer blocks, where each block contains linear layers, normalization layers and attention \textcolor{red}{?}
By design, the original patch order does not matter, which means that positional encodings need to be added to establish an order \citep{Dosovitskiy2020,Vaswani2017}.
\loadFigure{Figure:vit-arch}
\\
Attention is implemented by the following formula \citep{Vaswani2017}:
\begin{align}
    \text{attention}(Q,K,V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
\end{align}
The three matrices $Q,K,V$ are called query, keys and values respectively.
To understand what it is really doing it helps to look at the two components.
In a first step, the inner product between all queries $Q$ and all keys $K$ is considered.
This is rescaled with $\sqrt{d_k}$ and applying the softmax function consecutively results in a probability distribution over the elements.
The resulting matrix acts as an attending algorithm and can be thought of as a covariance matrix, where higher values in $(i,j)$ should indicate that the architecture should attend to the $j$-th token, when processing token $i$ \citep{Vaswani2017} \textcolor{red}{???}.    
\par
\subsection{Model Architecture}
A DINO head will be used to obtain weights for the ViT backbone.
The notation and terminology in the following subsection are adapted from \citep{Caron2021}.
As discussed by the authors in \citep{Caron2021}, the DINO head is essentially a teacher-student network.
Both teacher network and student network are parametrized by a weight vector $\theta_t$ and $\theta_s$ respectively.
The output $g_{\theta_s}$ of the student network is trained to equal the output $g_{\theta_t}$ of the teacher network, which is described as "SSL with Knowledge Distillation" by the authors \citep{Caron2021}.
An input image $x$ is passed through each network, resulting in the output which is used to calculate probability distributions $P_s$ and $P_t$ over $K$ variables for both networks, where the probability distributions are calculated as the normalized output of $g_{\theta_s}$ and of $g_{\theta_t}$:

\begin{align}
	P_s(x)^i = \frac{\exp(g_{\theta_s}(x)^i/\tau_s)}{\sum_{k=1}^{k=K}\exp(g_{\theta_s}(x)^k/\tau_s)}, \hspace{8pt} i=1,\dots,K
	\label{methods-softmax}
\end{align}

The normalization that is used is the softmax function (see \ref{methods-softmax}) and the $\tau_s > 0$ is a temperature parameter which influences the shape of the output distribution by manipulating the confidence of the predictions [QUELLE einfügen und mehr erläutern].
Note, that the exact number of dimensions $K$ is unknown, as no label knowledge is directly incorporated.
In the experiments $K$ will be set to \dots
\\
Let $H(p_1,p_2)$ denote the cross entropy of two probability distributions $p_1$, $p_2$, i.e. $H(p_1,p_2)=-p_1 \log p_2$.
Further assume a fixed teacher network parametrized by $\theta_t$.
Matching the output of the student network to the output of the teacher network can be reformulated as minimizing the cross-entropy of the teacher- and student distributions w.r.t. $P_s$:

\begin{align}
	\hat{\theta}_s = \min_{\theta_s}H(P_t(x),P_s(x))
\end{align}

The authors integrate SSL by adopting a multi-crop strategy [QUELLE].
Given the original input image $x$, several views of the same image are generated by applying augmentations to $x$.
The images of the set of augmentations called $V$ represent manipulated views of $x$, while global and local views correspond to views that enclose larger parts (e.g. >50\% receptive field(?)) and smaller parts (e.g. <50\% receptive field(?)) respectively [QUELLE].

\begin{align}
	\min_{\theta_s}\sum_{x \in \{x_1^g, x_2^g\}} \hspace{5pt} \sum_{\substack{ x'\in V, \\ x\neq x'}} H(P_t(x),P_s(x'))
	\label{methods-training-obj}
\end{align}

Equation \ref{methods-training-obj} is the training objective of the DINO head, which also reveals the setup of the feed-forward pass:
The outer sum collects all global views $x$, while the inner sum goes over all local views $x'\neq x$.
The global views are only passed to the teacher network and the local views are passed to the student network.
From these global-to-local correspondence [QUELLE, mehr zu cross entropy ergänzen] the teacher and student distribution should be as close as possible (entropy-wise).
\\
In this thesis, the number of global views is restricted to two and several local views are assumed, which adheres to the logic of the authors in \citep{Caron2021}. 
The parameter weights of the student network $\theta_s$ are updated by stochastic gradient descent with learning rate $\eta$ and fixed teacher network, i.e. [QUELLE]:

\begin{align}
	\theta_s \leftarrow \theta_s - \eta \nabla H(\bar{P}_t(x),P_s(x))
\end{align}

The parameter weights of $g_{\theta_t}$ are obtained by calculating an exponential moving average \citep{Grill2020,Caron2021}: 

\begin{align}
	\theta_t(T+1) \leftarrow \lambda \theta_t(T) + (1-\lambda) \theta_s(T).
	\label{methods-momentum-encoder}
\end{align}

A new estimate of $\theta_t$ at iteration $T+1$ is the result of the $\lambda$ weighted convex combination of the current value of $\theta_t$ and $\theta_s$ at time $T$ respectively.
The update rule in \ref{methods-momentum-encoder} is the same as a momentum encoder \citep{He2019} and $\lambda$ is set according to a cosine schedule \citep{Grill2020}.
\loadFigure{Figure:simclr-arch}
\loadTable{Table:dino-head-dim}
\loadTable{Table:normalizations}
\loadTable{Table:weights-init-method}
\loadFigure{Figure:labels-used-AUC-setting1}
\loadFigure{Figure:labels-used-AUC-setting2}
% \loadFigure{Figure:heatmap-geom}
% \loadFigure{Figure:heatmap-spatial}