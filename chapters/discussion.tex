\section{Discussion}
In this thesis, the performance of self-supervised learning methods on out-of-distribution detection (OoDD) for chest-x-ray images was examined and compared to supervised methods.
In the first setting (ID: \textit{No Finding}, OOD: \textit{Cardiomegaly}, \textit{Fracture}, \textit{Lung Opacity}, \textit{Pleural Effusion}, \textit{Pneumothorax}, \textit{Support Devices}) outlier exposure and custom augmentations were applied.
Unsupervised outlier exposure worked even with quite small label fractions, which is useful in the real world as although access to OOD samples is needed for better results, no fine-grained OOD class labels are needed.
Those improvements were only achieved for a small subset of pathologies and the fracture class still showed no large improvements.
\par
This was also observed for applying custom augmentations specifically tailored for the fracture class.
The augmentations can be interpreted as heuristic and no performance gain could be recognized.
The fracture class may look quite similar to the control class and the region of interest may be too small. 
Other normalizations for fracture could be tried out [SOURCE].
Another promising research direction could applying GANs \textcolor{red}{[ergänzen]}.
\par 
In the second setting (ID: \textit{Cardiomegaly}, \textit{Pneumothorax} OOD: \textit{Fracture}), DINO achieved comparable results to the supervised baseline when fine-tuned.
So for this setting, the pretrained weights extracted by the DINO learning objective proved to be useful.
Still, the SOTA performance of ODIN could not be reached.
\par
No satisfactory results could be achieved for the third setting (ID: \textit{Lung Opacity}, \textit{Pleural Effusion}, OOD: \textit{Fracture}, \textit{Pneumonia}).
One of the possible reasons: Similarity between the super ID class lung opacity and OOD class pneumonia is high. 
Therefore, the trained models might confuse the two classes. 
The better approach would be to learn the sub labels of the super ID class to better separate it from the OOD class, which would still require label knowledge. 
Another possibility would be to apply outlier exposure to setting three, which was successful in setting one. 
For that, further studies are needed. 
\par
The limited scope is one relevant limitation. Especially, the second and third setting contain only some different pathologies and the findings should be evaluated on different Chest X-ray datasets e.g. ChestX-ray8 \citep{Wang2017} and across the ID-OOD splits developed in \citep{Cao2020} to ensure validity and generalizability.
In addition, the resolution of the processed images is low. 
Small details of local textures might be missed and affect the pathology detection. 
Existing research methods could be applied to integrate images of higher resolution [SOURCES suchen].
\par
Further all examination are based on the assumption that the labels are correct [Weiter ausführen, auf verschiedene AUROC bei verschiedenen Klassen hinweisen.]
To ensure consistency with \citep{Berger2021} no label overlap between ID classes was assumed. 
In reality, this is no plausible assumption as the pathologies are \textbf{not} mutually exclusive.
Results of this thesis should therefore also be evaluated on datasets with label overlap and methods should be modified to handle the multi-label case.
\par
Apart from images, radiology reports are a further source of information that could be leveraged. 
Experts opinions of radiologists are often based on the combination of both. 
Datasets such as MIMIC-CXR \citep{Johnson2019} provide both images and reports. 
Multimodal methods such as CLIP \citep{Radford2021} can combine text and image data and it was recently shown, that they are powerful OOD detectors [Nikolas paper pre-print zitieren].
It was also already applied to x-ray images, therefore a transfer to ood detection for chest-xray images is straightforward.
\par
It could also be interesting to pretrain on larger datasets [SOURCE, maybe even merge datasets] and also reproduce the results on other imaging procedures (e.g. CT scans).
Further, as DINO has already produced promising results, one could also apply the updated DINO v2 version for better results and new insights [SOURCE].
Research should further put weight on exploring how the global crop scale for the DINO learning objective relates to the performance.
Finally, ablation studies should be carried out, that explore the impact of the ViT patch size on the ood detection performance.
Especially for small textural chest-x-ray incongruities, decreased patch sizes might be advisible.
\par
In conclusion, SSL can be adopted to novel disease ood detection for chest-xray images with few adjustments needed.
If fine-tuned, the results are comparable to supervised baseline methods.
Interestingly, for outlier exposure, no access to fine-grained OOD class labels is needed, which is different to standard computer vision benchmarks [SOURCES] and useful for real world adoption.
Overall, pretraining DINO on chest-x-ray images and using the pretrained weights for ood detection is a promising research direction for future work.
% \begin{itemize}
%     \item summarize findings
%     \item interpretation and implication
%         \begin{itemize}
%             \item setting 1: 
%                 \begin{itemize}
%                     \item custom augs unsuccessful
%                     \item unsupervised outlier exposure however worked even with quite small label fractions $\rightarrow$ which is useful in the real world as although access to OOD samples is needed for better results, no fine-grained OOD class labels are needed
%                     \item fracture class still no large improvements $\rightarrow$ fracture class may look quite similar to control class and ROI is too small?, try out other normalizations for fracture [SOURCES].
%                 \end{itemize} 
%         \item setting 2: 
%             \begin{itemize}
%                 \item SSL learning achieves comparable results when finetuned, so number of labeled samples can be reduced, SOTA performance of ODIN could not be reached
%             \end{itemize}
%         \item setting 3: 
%                 \begin{itemize}
%                     \item no satisfactory results could be achieved
%                     \item possible reasons: similarity between the super ID class lung opacity and OOD class pneumonia is high
%                     \item better approach: learn the sub labels of the super ID class for better separability $\rightarrow$ still requires label knowledge
%                     \item success of applying outlier exposure to setting 1 may transfer to setting 3 and label knowledge could be reduced $\rightarrow$ further studies
%                 \end{itemize}
%         \end{itemize}
%     \item limitations
%         \begin{itemize}
%             \item limited scope: findings should be evaluated on different Chest X-ray datasets e.g. ChestX-ray8 \citep{Wang2017} and across the ID-OOD splits developed in \citep{Cao2020} to ensure validity and generalizability
%             \item SupCon: did not result in satisfactory results $\rightarrow$ reason: did not find the right hyperparameter setup, training with AdamW optimizer probably more successful
%             \item resolution is low $\rightarrow$ work on methods that can integrate images of higher resolution [SOURCES suchen]
%             \item did not leverage radiology reports $\rightarrow$ multimodal methods e.g. CLIP [QUELLE] can combine text and image data and it was recently shown, that they are powerful OOD detectors [pre-print NIKOLAS]. Already applied to x-rays [QUELLE].
%         \end{itemize} 
%     \item further research directions:
%         \begin{itemize}
%             \item pretrain on larger datasets + also different imaging procedures e.g. CT scans
%             \item use DINO v2 
%             \item explore how the global crops scale influences the performance
%             \item how does the ViT patch size relate to the performance
%         \end{itemize}
%     \item conclusion:
%         \begin{itemize}
%             \item SSL can be adopted to novel disease ood detection for chest-xray images with few adjustments needed
%             \item if finetuned, the results are comparable to supervised baseline methods
%             \item interestingly, for outlier exposure, no access to fine-grained OOD class labels is needed, different to standard Computer-vision benchmarks [SOURCE]
%             \item Overall this represents a promising research direction for future work.
%         \end{itemize}
% \end{itemize}