\section{Introduction}
\raggedbottom
Nowadays, most Machine Learning (ML) applications operate under closed-world assumptions.
Models are trained on the \textit{train set}, hyperparameters are tuned on the \textit{validation set} and the true performance is evaluated on a held-out \textit{test set}, which was not included in the training process.
It is implicitly assumed, that the \textit{test set} serves as a proxy for the true performance which would be encountered, when models are deployed in real-world applications.
\par
The performance of ML models to accurately predict novel samples is known as \textit{generalization} \citep{Bishop2006}.
Recent works question the generalization capability of ML models trained under closed-world assumptions because of lower performance \citep{Recht2018,Zech2018}.
Performance issues can be caused by unsuitable input data and a strategy to deal with this problem is out-of-distribution detection (OoDD).
Unsuitable samples should be identified, and the model's prediction is omitted.
The data known to the classifier (train and validation set) is described as \textit{in-distribution} (ID) while new, often unknown data represents samples from \textit{out-of-distribution} (OOD).
A reliable model output on OOD samples cannot be guaranteed, and a separate consideration may be reasonable.
\par
These detection tasks are especially important in high-risk-environments such as medicine, where human intervention is often required. 
A tool used regulary in patients with dyspnea or thoracic pain are chest-x-rays.
Common pathologies detected in x-rays are e.g. pneumonia, cardiomegaly, pleural effusion, atelectasis, edema, pneumothorax and fractures. 
Because of constant time pressure in emergency rooms and the high number of patients it could be a great support for radiologists to get x-rays pre-examined by artificial intelligence (AI) systems.
\par
An important factor for the acceptance of such systems is the right calibration to limit their predictive overconfidence, because wrong detections could be dangerous especially in medicine.
Deep learning in medical imaging has shown promising results in the past. 
For example, Rajpurkar et. al. introduce CheXNet and achieve comparable performance to radiologists in detecting different pathologies in chest-x-rays \citep{Rajpurkar2017}.
On the other hand, failures of deep learning models in medical imaging have been identified in different studies.
DeGrave et. al. demonstrate that AI systems deployed on chest radiographs can rely on confounding factors specific to the data set \citep{Degrave2021}.
The considered models exhibit shortcuts and learn to detect pathologies based on features that are not clinically relevant \citep{Degrave2021}.
Rayner et. al. analyse the impact of a selection bias related to training labels and conclude that benchmark performance in the literature does not necessarily translate to clinical applicability \citep{Rayner2019}.
Zech et. al. also show that the performance of pneumonia screening of chest X-rays from outside hospitals was significantly lower than that of chest X-rays from the original hospital system in three out of five cases \citep{Zech2018}.
Preprocessing the input x-ray images and limiting prediction outside the model's competence could be a part of the solution to these problems.
\par
To apply OoDD to chest-x-rays, Cao et. al. distinguish three different use cases \citep{Cao2020}.
In the first use-case, images that are unrelated to x-ray-images should be filtered out, e.g. they might originate from a different imaging procedure.
In the second use-case the OOD images are x-ray-images, but they are acquired incorrectly and because of flawed image characteristics (e.g. high contrast, rotation etc.) a model prediction should be avoided.
The third use-case considers x-ray images of unseen or novel pathologies as OOD samples and would also mark them as unknown.
% In this thesis, the focus is mainly on the third use case, which is unsolved to a large extent for x-ray-images.
% As a collection of chest-x-ray images, the CheXpert dataset is used \citep{Irvin2019} and the ID-OOD splits are adapted from \citep{Berger2021}.
\par
In \citep{Cao2020} OoDD of novel diseases only scores close to a random guess of 50\% AUROC across a large sample of unsupervised and supervised methods \citep{Cao2020}.
However, the authors of \citep{Berger2021} achieve better performance with further adoptions and use a comparable but different data set.
But, these improvements are based on supervised classifiers leading to limitations in the real world, because the acquisition of labels often has high costs. 
In addition to that, supervised classifiers lead to highly specific weights.
\par
Another option is to appy self-supervised learning (SSL), which does not assume prior label knowledge and extracts more general representations of the input data.
In computer vision, SSL is often implemented by augmenting the input images (e.g. image cropping or image rotation) and training the model with a specific learning objective.
Commonly used learning objectives such as DINO \citep{Caron2021} and SimCLR \citep{Chen2020} report impressive results in the field of computer vision and especially DINO models show unsupervised semantic segmentation capabilities \citep{Caron2021}.
\par
Both models are build by combining a backbone architecture functioning as a feature extractor and a projection network \citep{Caron2021,Chen2020}. 
The backbone architecture used by Caron et. al. is the Vision Transformer (ViT) \citep{Caron2021}.
The ViT is a transformer architecture \citep{Vaswani2017} reformulated to accept images as input \citep{Dosovitskiy2020}.
In a recent study, Fort et. al. used pretrained ViT models to achieve high performance on a range of OOD detection tasks \citep{Fort2021}.
This motivates the use of ViT models for OoDD of chest-x-ray images.
\par
Because of the limitations of supervised classifiers and the promising results of SSL methods, the goal of this thesis is to investigate the performance of SSL methods on OoDD of chest-x-ray images and to compare to supervised methods.
Also, necessary adaptions of the methods to accept chest-x-ray images as inputs are analysed. 