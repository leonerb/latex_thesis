@Article{Dosovitskiy2020,
  author   = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  title    = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  pages    = {arXiv:2010.11929},
  url      = {https://ui.adsabs.harvard.edu/abs/2020arXiv201011929D},
  abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
  journal  = {arXiv e-prints},
  keywords = {Computer Science - Computer Vision and Pattern Recognition Computer Science - Artificial Intelligence Computer Science - Machine Learning},
  type     = {Journal Article},
  year     = {2020},
}

@Article{Vaswani2017,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Caron2021,
  author    = {Mathilde Caron and
               Hugo Touvron and
               Ishan Misra and
               Herv{\'{e}} J{\'{e}}gou and
               Julien Mairal and
               Piotr Bojanowski and
               Armand Joulin},
  title     = {Emerging Properties in Self-Supervised Vision Transformers},
  journal   = {CoRR},
  volume    = {abs/2104.14294},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.14294},
  eprinttype = {arXiv},
  eprint    = {2104.14294},
  timestamp = {Tue, 04 May 2021 15:12:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-14294.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Grill2020,
       author = {{Grill}, Jean-Bastien and {Strub}, Florian and {Altch{\'e}}, Florent and {Tallec}, Corentin and {Richemond}, Pierre H. and {Buchatskaya}, Elena and {Doersch}, Carl and {Avila Pires}, Bernardo and {Guo}, Zhaohan Daniel and {Gheshlaghi Azar}, Mohammad and {Piot}, Bilal and {Kavukcuoglu}, Koray and {Munos}, R{\'e}mi and {Valko}, Michal},
        title = "{Bootstrap your own latent: A new approach to self-supervised Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
         year = 2020,
        month = jun,
          eid = {arXiv:2006.07733},
        pages = {arXiv:2006.07733},
archivePrefix = {arXiv},
       eprint = {2006.07733},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv200607733G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{He2019,
       author = {{He}, Kaiming and {Fan}, Haoqi and {Wu}, Yuxin and {Xie}, Saining and {Girshick}, Ross},
        title = "{Momentum Contrast for Unsupervised Visual Representation Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2019,
        month = nov,
          eid = {arXiv:1911.05722},
        pages = {arXiv:1911.05722},
archivePrefix = {arXiv},
       eprint = {1911.05722},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv191105722H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Irvin2019,
       author = {{Irvin}, Jeremy and {Rajpurkar}, Pranav and {Ko}, Michael and {Yu}, Yifan and {Ciurea-Ilcus}, Silviana and {Chute}, Chris and {Marklund}, Henrik and {Haghgoo}, Behzad and {Ball}, Robyn and {Shpanskaya}, Katie and {Seekins}, Jayne and {Mong}, David A. and {Halabi}, Safwan S. and {Sandberg}, Jesse K. and {Jones}, Ricky and {Larson}, David B. and {Langlotz}, Curtis P. and {Patel}, Bhavik N. and {Lungren}, Matthew P. and {Ng}, Andrew Y.},
        title = "{CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
         year = 2019,
        month = jan,
          eid = {arXiv:1901.07031},
        pages = {arXiv:1901.07031},
archivePrefix = {arXiv},
       eprint = {1901.07031},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190107031I},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


